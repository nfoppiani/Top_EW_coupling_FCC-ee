\section{Week 03}

\subsection{03/08/2015}

\textbf{Other leptons Whizard simulations}

We have copied and Marlin all the other simulations files with one leptons (muons or electrons) in the final state.\\
We would like to analyze the energy-angle distribution to understand if the boundary effect are due to some diagrams which interferes (only in the electrons case) or if they are due to something else.

\textbf{Likelihood fit}

After a lesson about the likelihood and how to fit an histogram by finding the minimum of the likelihood (thanks to Patrick), we started fitting our energy-angle distribution for the electrons with a model $S_0 + a f_1$, where $S_0$ is the standard model distribution and $f_1$ is a BSM correction.\\

We have started from two histograms of $S_0$ and $f_1$ with 200 bins in each dimension and reduced energy between 0.114246 and 1, and $cos\theta$ between -1 and 1 (obviously).\\ We have then normalized the distribution so we can use them as probability density function. So we have reproduced our distribution with these settings and use the likelihood formula:
\[L=-\sum_{events} log(S_0+a f_1) = -\sum_{bins} N_{bin} log(S_0+a f_1)\]
\[L'=-\sum N \frac{f_1}{S_0 + a f_1}  and  L''= \sum N \frac{f_1^2}{(S_0 + a f_1)^2}\]

where N is the number of entries in the selected bin of the montecarlo histogram, and $S_0$ and $f_1$ are the numbers of the entries in the histograms of the probability density function.

Then we could use the tangent method to find iteratively the minimum value (that we expect to be 0).
\[a_0 = a - \frac{L'(a)}{L''(a)}\]

and after all we can estimate the error with \[\sigma = \sqrt{\frac{1}{L''(a_0)}}\]

We have found some errors while calculating the Likelihood and its derivatives cause to the fact that $S_0$ and $f_1$ became very near to 0 in some points. We don't now how to solve yet.

\subsection{04/08/2015}

\textbf{TChain}

We have just discovered a new method to process a lot of Root files containing tree without using glob.
We simply need to define a TChain object:\\
mychain = TChain("MyTreeName")
where MyTreeName is the name of the trees inside the root files.\\
Then we can add all the root files to the chain by using:
mychain.Add("*.root")\\
and then we can loop on all the events dealing mychain as a tree.

\textbf{Likelihood fit part 2}

We found the problem in the code: strangely, if we look to the $S_0$ and $f_1$, we find that the bins (0,*) and (*,0) contains exactly 0 entries. So during the calculation of the derivatives we find several problems in dividing by zero. We solve the problem by simply don't consider these bins. The result is pretty strange because, starting with an initial value of a=0.1 we obtain a result of $a=0.2 \pm 0.01$ with a first derivative very close to zero. This result is only quite reasonable because we expect something close to zero, with 0 into the errorbar.

After a little time we found out that the first bins (*,0) and (0,*) and the last bins (*,201) and (201,*) are the overflow and the underflow of the histograms, so we need to use the method GetBinContent on the bin between 1 and 200 in both directions. The result hasn't changed and we tried to plot the marginal distributions. But this result is not satisfactory.

\subsection{05/08/2015}

\textbf{Physics lesson at Gigi's home}

We have attended a physics lesson at Gigi's home about how to do physics at e+e- colliders.

\subsection{06/08/2015}



\textbf{Leptons tree and effective invariant mass}

We have created 6 trees (one for each possible lepton in the final state) with only the variables we need. In particular there are the energy (and reduced energy), the three component of the momentum, the polar angle, and the invariant mass of the two electrons after radiating photons. This invariant mass is the effective energy at which the collisions happen, and the mean is 363.7 GeV. 

\subsection{07/08/2015}

\textbf{Corrections to the likelihood}

Together with Patrick, realized that the likelihood we defined on Monday 03/08/2015 was not correct. In fact, the normalization factor that turns the cross sections in the probabilities depends on the parameter $a$, and we have also to consider the probability that our MonteCarlo generator produced $N$ events, if the mean value of events is $\mu$.
Let $S_{tot}$, $f_{tot}$ and $N_{tot}$ be the sum of the bins in our range of study (we may want to make some cuts in the values of $\cos\theta$ and the reduced energy $x$) of the Standard Model cross section, of the correction-to-SM cross sections, and the number of events generated by Whizard. Let the luminosity (integrated over the experiment time) be $K$. Then, the probability of having $N$ events produced in our range of study is:
\[
\frac{\mu^Ne^{-\mu}}{N!} \quad\rightarrow\quad \frac{e^{\frac{-(N-\mu)^2}{2\mu}}}{\sqrt{2\pi\mu}}
\]
where $N=KS_{tot}$ and $\mu = K(S_{tot}+f_{tot})$.
Therefore, the likelihood is:
\[
L = \Bigl(\prod_{bins}N_{bin}\frac{S_{bin}+af_{bin}}{S_{tot}+af_{tot}}\Bigr)\frac{e^{\frac{-(N-\mu)^2}{2\mu}}}{\sqrt{2\pi\mu}}
\]
We would like to maximize the likelihood, by minimizing the following quantity:
\begin{equation}
\begin{split}
\mathcal{L} &= -\log{L} +\frac{1}{2}\log(2\pi) =\\
&=- \sum_{bin}\log(S_{bin}+af_{bin})+N_{tot}\log(S_{tot}+af_{tot})-\frac{1}{2}\log\mu+\frac{(\mu-N)^2}{2\mu} =\\
&=- \sum_{bin}\log(S_{bin}+af_{bin})+N_{tot}\log(S_{tot}+af_{tot})-\frac{1}{2}\log\Bigl(N_{tot}\frac{S_{tot}+af_{tot}}{S_{tot}}\Bigr)+N_{tot}\frac{(af_{tot})^2}{2S_{tot}(S_{tot}+af_{tot})}
\end{split}
\end{equation}